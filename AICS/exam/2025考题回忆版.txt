填空：
1. 神经网络的训练过程主要包括__________和__________两个过程。训练过程中，训练过程中，训练的特征少，拟合函数无法有效逼近训练集，导致误差较大的现象叫做__________；在训练数据集上的误差很低，但在验证数据集上的误差很大的现象叫做__________。为了提高神经网络的泛化能力，可以使用许多不同形式的__________方法，包括参数范数惩罚、稀疏化、Bagging 集成、Dropout、提前终止等。

2. 大模型的训练分为__________两个主要阶段。其中，__________阶段使用大量无标注数据，而__________阶段则针对特定任务进行优化。为提升大模型训练效率，常采用分布式训练策略，根据分布式计算中的分区情况的不同，可划分为多种并行形式。其中，__________对输入数据进行分区；__________对模型参数进行分区；混合并行同事对输入数据和模型参数进行分区

3. 智能计算系统的抽象结构中，设备端板卡级的存储资源为__________，芯片级的存储资源为__________，cluster级的存储资源为__________，core 级的存储资源为__________

4. 一个卷积维度的计算题

简答：
1. 请简要比较一阶段目标检测方法与两阶段目标检测方法的原理，并结合典型代表方法（如 YOLO 系列、R-CNN 系列、SSD 系列、DETR 等）说明它们各自所属的类别，并分析两种类型的检测方法在检测精度与运行速度方面的差异。

2. 典型深度学习编程框架的整体架构可化为四大核心模块，分别是哪几种模块，请简述并说明其作用。正向计算图构建时，一般会支持静态图模式或动态图模式，这两种执行模式有什么特点及优缺点？反向计算图构建的求导机理可以归纳为哪几种方式？哪种方式目前应用于主流深度学习编程框架中？

3. 简述单核深度学习处理器的片内存储、访存行为以及指令解码过程与传统 CPU 上的区别。同时，结合对 Scratchpad Memory（SPM）与 Cache 的对比，分析深度学习处理器中更倾向于采用 SPM 的原因。

4. 在大模型系统软件中，稀疏注意力机制和 Flash Attention 能够对大模型进行优化，他们有什么区别和联系？在大模型基础硬件中，胖树（Fat tree）、Dragonfly 和 3D 是计算集群中的网络拓扑结构，请简述这三者的主要内容和优缺点。

5. 假设 DLP 芯片中有 4 个 Cluster，每个 Cluster 中有 4 个 Core，Host 端启动一个任务类型为 UNION1、任务规模为 [2, 1, 4] 的任务，请在下表中填写 Kernel 程序执行时读取到的并行变量的值。
(taskId	
taskIdX	
taskIdY	
taskIdZ	
taskDimX	
taskDimY	
taskDimZ	
taskDim	
coreId	
coreDim	
clusterId	
clusterDim)

参考题：
https://blog.csdn.net/lzheng012019/article/details/139441457
https://zhuanlan.zhihu.com/p/1916943773373535671
